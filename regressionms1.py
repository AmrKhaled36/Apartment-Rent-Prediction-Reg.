# -*- coding: utf-8 -*-
"""RegressionMS1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBYVDA_4iRCfGRrZFSL4Bh1vl_jv9PJj

# Importing libraries, Reading the CSV, And initial look.
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn import linear_model
from sklearn import metrics
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score
import re
import pickle

df = pd.read_csv('ApartmentRentPrediction.csv')
df.describe()

df.info()

"""# Preprocessing"""

def MoneyConversion(text):
    money_values = re.findall(r'\$?[\d,]+', str(text))
    converted_values = [int(value.replace('$', '').replace(',', '')) for value in money_values]
    return sum(converted_values) if converted_values else 0

df['price_display'] = df['price_display'].apply(MoneyConversion)

# print(df.isnull().sum() * 100 / len(df))
# print(df['price_display']);

def fet_encod(x,y):
    average_values = x.groupby(y)['price_display'].median()
    sorted_average_values = average_values.sort_values()
    with open(f'{y}_Reg.pkl', 'wb') as model_file:
      pickle.dump(sorted_average_values, model_file)
    x[y] = x[y].map(sorted_average_values.rank())

fet_encod(df,"cityname")
fet_encod(df,'state')
fet_encod(df,"address")

df.dropna(subset=['longitude','latitude', 'state','cityname','bedrooms','bathrooms'], inplace=True)

pets_allowed_mvalue = df['pets_allowed'].mode()[0]

df['pets_allowed'].fillna(pets_allowed_mvalue, inplace=True)

df['address'] = df.apply(lambda row: row['cityname'] if pd.isnull(row['address']) else row['address'], axis=1)
df.loc[0, :]

df.drop('price', inplace = True, axis = 1)




print(df.isnull().sum())

# Input string containing substrings separated by commas
input_string = df['amenities']
substring_set = dict()
for value in input_string:
  if type(value) != str:
    continue
  substrings = value.split(',')
  for j in substrings:
    substring_set[j] = [0, 0]

substring_set

for i in range(df.shape[0]):
  # print(df.iloc[i, 4], i)
  if type(df.iloc[i, 4]) != str:
    continue
  s = df.iloc[i, 4].split(',')
  for j in s:
    substring_set[j][0] += df.iloc[i, 11]
    substring_set[j][1] += 1

l = []

for key, value in substring_set.items():
  l.append((value[0]/value[1], key))

l.sort()
for i in range(len(l)):
  substring_set[l[i][1]] = i

for i in range(df.shape[0]):
  if type(df.iloc[i, 4]) != str:
    df.iloc[i, 4] = 0
    continue
  s = df.iloc[i, 4].split(',')
  tmp = 0
  for j in s:
    tmp += (1 << (substring_set[j]))
  df.iloc[i, 4] = tmp

print(df.isnull().sum())

# Apply ceil function


df['bathrooms'] = df['bathrooms'].apply(np.ceil)

# Identify numeric columns
numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns

# Detect columns with outliers
columns_with_outliers = []
for column in numeric_columns:
    z_scores = stats.zscore(df[column], nan_policy = 'omit')
    if (z_scores < -3).any():
      columns_with_outliers.append(column)
    elif (z_scores > 3).any():
      columns_with_outliers.append(column)

if columns_with_outliers:
    print("Columns with outliers:", columns_with_outliers)
else:
    print("No columns with outliers detected.")

plt.figure(figsize=(8, 6))
plt.boxplot(df['bathrooms'])
plt.title('Box Plot of bathrooms')
plt.ylabel('Bathrooms')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['bedrooms'])
plt.title('Box Plot of bedrooms')
plt.ylabel('Bedrooms')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['square_feet'])
plt.title('Box Plot of square_feet')
plt.ylabel('Square_feet')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['latitude'])
plt.title('Box Plot of latitude')
plt.ylabel('Latitude')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['longitude'])
plt.title('Box Plot of longitude')
plt.ylabel('Longitude')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['price_display'])
plt.title('Box Plot of price')
plt.ylabel('Price')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

# Calculate z-scores for each value in the DataFrame
Z = stats.zscore(df.select_dtypes(include=['int64', 'float64']), nan_policy = 'omit')

#Drop outliers with z-score equal to or greater than 3
df.drop(df.index[(np.abs(Z) > 3).any(axis=1)], inplace=True)



cityname_mode = df['cityname'].mode()[0]
state_mode = df['state'].mode()[0]
square_feet_mean = df['square_feet'].mean()

with open('fillna_Reg.pkl', 'wb') as model_file:
    pickle.dump({'cityname': cityname_mode, 'state':state_mode, 'square_feet': square_feet_mean}, model_file)

print(df.isnull().sum())

plt.figure(figsize=(8, 6))  # Set the size of the plot
plt.boxplot(df['bathrooms'])
plt.title('Box Plot of bathrooms')
plt.ylabel('bathrooms')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['bedrooms'])
plt.title('Box Plot of bedrooms')
plt.ylabel('Bedrooms')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['latitude'])
plt.title('Box Plot of latitude')
plt.ylabel('Latitude')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['longitude'])
plt.title('Box Plot of longitude')
plt.ylabel('Longitude')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['square_feet'])
plt.title('Box Plot of square_feet')
plt.ylabel('Square_feet')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot(df['price_display'])
plt.title('Box Plot of price')
plt.ylabel('Price')
plt.grid(True)  # Add gridlines
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

sns.displot(df['square_feet'])

# Encode categorical columns
cat_cols = ['category', 'title', 'body', 'currency', 'fee','has_photo', 'pets_allowed', 'price_type', 'source']
def Feature_Encoder(df,cat_cols):
    for c in cat_cols:
        lbl = LabelEncoder()
        lbl.fit(list(df[c].values))
        df[c] = lbl.transform(list(df[c].values))
    return df

# Min-Max Scaling on address
df['address'] = (df['address'] - df['address'].min()) / (df['address'].max() - df['address'].min())

#Encoding ID column
tmp = df.copy()
df['id'] = range(1, len(df) + 1)
Feature_Encoder(df,cat_cols)
df.head()

df.drop(columns=['address','category', 'title', 'body', 'currency', 'fee','has_photo', 'pets_allowed', 'price_type', 'source', 'latitude', 'longitude', 'id', 'time'], inplace = True)

print(df.head())

"""# Visualizing"""

price_type_counts = tmp['price_type'].value_counts()

# Create the bar chart
plt.figure(figsize=(8, 6))
price_type_counts.plot(kind='bar', color='skyblue')
plt.title('Distribution of Price Types')
plt.xlabel('Price Type')
plt.ylabel('Count')
plt.xticks(rotation=0)  # Rotate x-axis labels for better readability
plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add gridlines to the y-axis
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

pets_allowed_counts = tmp['pets_allowed'].value_counts()
# Create the pie chart
plt.figure(figsize=(8, 6))
plt.pie(pets_allowed_counts, labels=pets_allowed_counts.index, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgreen', 'red', 'green'])
plt.title('Pets Allowed Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

# Extracting data for scatter plot
x = tmp['square_feet']
y = tmp['price_display']

# Create the scatter plot
plt.figure(figsize=(10, 10))
plt.scatter(x, y, color='blue', alpha=0.5)  # Create the scatter plot
plt.title('Relation between square_feet and Price')
plt.xlabel('Square Feet')
plt.ylabel('Price')
plt.grid(True)
# plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

# Extracting data for scatter plot
x = tmp['cityname']
y = tmp['price_display']

# Create the scatter plot
plt.figure(figsize=(10, 10))
plt.scatter(x, y, color='blue', alpha=0.5)  # Create the scatter plot
plt.title('Relation between cityname and Price')
plt.xlabel('cityname')
plt.ylabel('Price')
plt.grid(True)
# plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

Y=df['price_display']
df_info = df.iloc[:, :]
corr = df_info.corr()
top_feature = corr.index[abs(corr['price_display'])>0.15]
plt.subplots(figsize=(12, 8))
top_corr = df_info[top_feature].corr()
sns.heatmap(top_corr, annot=True)
plt.show()
# top_feature = top_feature.delete(-1)

"""# Feature Selection and Applying Models"""

# Feature selection
selected_features = ['cityname', 'square_feet', 'state']
X = df[selected_features].values
Y = df['price_display'].values

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True ,random_state=10)

with open('ds_Reg.pkl', 'wb') as model_file:
    pickle.dump({'X': X, 'Y': Y}, model_file)

model = LinearRegression()
model.fit(X_train, Y_train)

y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

mse_train = mean_squared_error(Y_train, y_pred_train)
mse_test = mean_squared_error(Y_test, y_pred_test)

print(f"Train MSE: {mse_train}, Test MSE: {mse_test}")
print("R^2 score(Train):", r2_score(Y_train, y_pred_train))
print("R^2 score(Test):", r2_score(Y_test, y_pred_test))

X_train2, X_valid, Y_train2, Y_valid = train_test_split(X_train, Y_train, test_size=0.25, shuffle=True ,random_state=10)


poly_features = PolynomialFeatures(degree=3)

X_train_poly = poly_features.fit_transform(X_train2)
# fit the transformed features to Linear Regression
poly_model = linear_model.LinearRegression()
poly_model.fit(X_train_poly, Y_train2)

# predicting on training data-set
y_train_predicted = poly_model.predict(X_train_poly)

# predicting on validation data-set
valid_prediction = poly_model.predict(poly_features.fit_transform(X_valid))

# predicting on test test
test_prediction = poly_model.predict(poly_features.fit_transform(X_test))

print('Mean Square Error(Train)', metrics.mean_squared_error(Y_train2, y_train_predicted))
print("R^2 score(train):", r2_score(Y_train2, y_train_predicted))

print('Mean Square Error(valid)', metrics.mean_squared_error(Y_valid, valid_prediction))
print("R^2 score(valid)", r2_score(Y_valid, valid_prediction))

print('Mean Square Error(test)', metrics.mean_squared_error(Y_test, test_prediction))
print("R^2 score(test):", r2_score(Y_test, test_prediction))

X_train3, X_valid, Y_train3, Y_valid = train_test_split(X_train, Y_train, test_size=0.25, shuffle=True ,random_state=10)



# Initialize the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, max_depth=8, min_samples_split=10, min_samples_leaf=4, random_state=16)

# Train the model
rf_model.fit(X_train, Y_train)

# Predict on the test set
y_pred_train = rf_model.predict(X_train)
y_pred_valid = rf_model.predict(X_valid)
y_pred_test = rf_model.predict(X_test)

# Evaluate the model
print('Mean Squared Error(train):', mean_squared_error(Y_train, y_pred_train))
print("R^2 score(train):", r2_score(Y_train, y_pred_train))

print('Mean Squared Error(valid):', mean_squared_error(Y_valid, y_pred_valid))
print("R^2 score(valid):", r2_score(Y_valid, y_pred_valid))

print('Mean Squared Error(test):', mean_squared_error(Y_test, y_pred_test))
print("R^2 score(test):", r2_score(Y_test, y_pred_test))

with open('RF_Reg.pkl', 'wb') as model_file:
    pickle.dump(rf_model, model_file)